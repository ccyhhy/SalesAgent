# crawl_manager.py
# 2025-12-12 æœ€ç»ˆå®‰å…¨ç‰ˆ
# åŠŸèƒ½ï¼šé€‚é…å¿«ä»£ç†éš§é“ï¼Œè‡ªåŠ¨å¤„ç†è®¤è¯ï¼ŒV2æ’ä»¶é˜²å¼¹çª—

from DrissionPage import ChromiumPage, ChromiumOptions
import time
import urllib.parse
import config  # è¯»å–æœ¬åœ°é…ç½®
import os
import shutil

class Crawler:
    def __init__(self):
        print("\nğŸš€ [å¯åŠ¨] æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...")
        
        co = ChromiumOptions()
        co.no_imgs(True)  # ä¸åŠ è½½å›¾ç‰‡
        co.mute(True)     # é™éŸ³
        
        # ============================================================
        # 1. ä»£ç†é…ç½® (ä½¿ç”¨ config ä¸­çš„å˜é‡)
        # ============================================================
        if hasattr(config, 'PROXY_HOST') and config.PROXY_HOST:
            print(f"   ğŸ“‹ è¯»å–ä»£ç† -> {config.PROXY_HOST}:{config.PROXY_PORT}")
            
            # A. å¼ºåˆ¶è®¾ç½®ä»£ç†æœåŠ¡å™¨
            co.set_argument(f'--proxy-server={config.PROXY_HOST}:{config.PROXY_PORT}')
            
            # B. åŠ è½½è‡ªåŠ¨è®¤è¯æ’ä»¶ (Manifest V2 - å½»åº•è§£å†³å¼¹çª—)
            if hasattr(config, 'PROXY_USER') and config.PROXY_USER:
                self.plugin_path = self._create_auth_plugin(config.PROXY_USER, config.PROXY_PASS)
                co.add_extension(self.plugin_path)
                print(f"   ğŸ”Œ [æ’ä»¶] è‡ªåŠ¨è®¤è¯æ¨¡å—å·²åŠ è½½")
        else:
            print("   âš ï¸ æœªæ£€æµ‹åˆ°ä»£ç†é…ç½®ï¼Œä½¿ç”¨ç›´è¿...")

        # ============================================================
        # 2. æŠ—å¹²æ‰°é…ç½® (é€‚é…æ ¡å›­ç½‘/æ¢¯å­ç¯å¢ƒ)
        # ============================================================
        co.set_argument('--no-sandbox')
        co.set_argument('--disable-gpu')
        co.set_argument('--ignore-certificate-errors')
        
        # ç¦ç”¨ QUIC å’Œ WebRTCï¼Œé˜²æ­¢è¿æ¥é‡ç½®å’ŒIPæ³„éœ²
        co.set_argument('--disable-quic')
        co.set_argument('--disable-webrtc')
        
        # ä¼ªè£…å»è‡ªåŠ¨åŒ–ç‰¹å¾
        co.set_argument('--disable-blink-features=AutomationControlled')

        # 3. æŒ‡å®šç”¨æˆ·æ•°æ®ç›®å½•
        user_data_path = os.path.join(os.getcwd(), 'browser_data')
        co.set_user_data_path(user_data_path)
        
        try:
            self.page = ChromiumPage(co)
            # è®¾ç½® 30ç§’ è¶…æ—¶
            self.page.set.timeouts(30)
            
            print(f"   âœ… æµè§ˆå™¨å·²å¯åŠ¨")
            
            # ã€è‡ªæ£€ç¯èŠ‚ã€‘
            print("   ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨éªŒè¯ç½‘ç»œ...", end="")
            self.page.get('http://httpbin.org/ip', retry=1, show_errmsg=False, timeout=15)
            if "origin" in self.page.html:
                print(" -> é€šç•…!")
            else:
                print(" -> (æ— å“åº”ï¼Œå°è¯•ç»§ç»­)")
            
        except Exception as e:
            print(f"\n   âŒ å¯åŠ¨å¤±è´¥: {e}")
            print("   ğŸ’¡ æç¤º: æ ¡å›­ç½‘ç”¨æˆ·è¯·ç¡®ä¿æ¢¯å­å¼€å¯äº† [TUNæ¨¡å¼] å’Œ [å…¨å±€æ¨¡å¼]ã€‚")

    def _create_auth_plugin(self, user, password):
        """
        ç”Ÿæˆ Chrome è®¤è¯æ’ä»¶ (Manifest V2)
        """
        plugin_path = os.path.join(os.getcwd(), 'proxy_auth_plugin')
        
        # æ¸…ç†æ—§æ’ä»¶
        if os.path.exists(plugin_path):
            try: shutil.rmtree(plugin_path)
            except: pass
        os.makedirs(plugin_path)

        # V2 ç‰ˆæœ¬ Manifest (æœ€ç¨³)
        manifest_json = """
        {
            "version": "1.0.0",
            "manifest_version": 2,
            "name": "Chrome Proxy Auth Helper",
            "permissions": [
                "proxy", "tabs", "unlimitedStorage", "storage", 
                "<all_urls>", "webRequest", "webRequestBlocking"
            ],
            "background": { "scripts": ["background.js"] },
            "minimum_chrome_version":"22.0.0"
        }
        """

        # èƒŒæ™¯è„šæœ¬ (éœ€è¦è¯»å– config ä¸­çš„ host/port)
        background_js = f"""
        var config = {{
            mode: "fixed_servers",
            rules: {{
                singleProxy: {{
                    scheme: "http",
                    host: "{config.PROXY_HOST}",
                    port: parseInt({config.PROXY_PORT})
                }},
                bypassList: ["localhost"]
            }}
        }};

        chrome.proxy.settings.set({{value: config, scope: "regular"}}, function() {{}});

        function callbackFn(details) {{
            return {{
                authCredentials: {{
                    username: "{user}",
                    password: "{password}"
                }}
            }};
        }}

        chrome.webRequest.onAuthRequired.addListener(
            callbackFn,
            {{urls: ["<all_urls>"]}},
            ['blocking']
        );
        """

        with open(os.path.join(plugin_path, "manifest.json"), "w", encoding='utf-8') as f:
            f.write(manifest_json)
        with open(os.path.join(plugin_path, "background.js"), "w", encoding='utf-8') as f:
            f.write(background_js)
        
        return plugin_path

    def search_and_crawl(self, company_name):
        """æ‰§è¡Œæœç´¢å’ŒæŠ“å–"""
        if not hasattr(self, 'page') or not self.page: return "æµè§ˆå™¨æœªå¯åŠ¨"

        print(f"   ğŸ” æœç´¢: {company_name}...")
        abstract = ""
        website_text = ""
        
        try:
            # 1. ç™¾åº¦æœç´¢
            query = urllib.parse.quote(f"{company_name} å®˜ç½‘")
            self.page.get(f"{config.SEARCH_ENGINE_URL}{query}", retry=3, interval=2, timeout=30)
            
            # éªŒè¯ç å¤„ç†
            if "å®‰å…¨éªŒè¯" in self.page.title or "wappass" in self.page.url:
                print("   âš ï¸ è§¦å‘éªŒè¯ç ï¼Œç­‰å¾… 15 ç§’...")
                time.sleep(15)

            # æŠ“æ‘˜è¦
            res = self.page.eles('css:#content_left .result', timeout=3)
            for r in res[:3]: abstract += r.text + "\n"

            # 2. è¿›å®˜ç½‘
            target_link = None
            res_list = self.page.eles('css:#content_left .result', timeout=3)
            for res in res_list[:5]:
                title = res.ele('tag:h3').text
                # æ’é™¤éå®˜ç½‘é“¾æ¥
                if any(x in title for x in ['æ‹›è˜', 'çˆ±ä¼æŸ¥', 'å¤©çœ¼æŸ¥', 'ä¼æŸ¥æŸ¥', '58', 'ç™¾ç§‘']):
                    continue
                target_link = res.ele('tag:a')
                break
            
            if target_link:
                print("   ğŸ”— è¿›å®˜ç½‘...", end="")
                target_link.click()
                
                self.page.wait.new_tab()
                new_tab = self.page.latest_tab
                
                try:
                    new_tab.wait.ele('tag:body', timeout=20)
                    new_tab.scroll.to_bottom()
                    time.sleep(2)
                    website_text = new_tab.ele('tag:body').text
                    website_text = '\n'.join([l.strip() for l in website_text.split('\n') if l.strip()])
                except:
                    website_text = "å®˜ç½‘åŠ è½½è¶…æ—¶"
                
                new_tab.close()
                print(" å®Œæˆ")
            else:
                print(" (æ— å®˜ç½‘é“¾æ¥)")
                website_text = "æœªæ‰¾åˆ°å®˜ç½‘é“¾æ¥"

        except Exception as e:
            print(f"   âŒ æŠ“å–ä¸­æ–­: {e}")
            website_text = f"Error: {e}"

        return f"ã€ç™¾åº¦æ‘˜è¦ã€‘\n{abstract}\n\nã€å®˜ç½‘å†…å®¹ã€‘\n{website_text[:5000]}"

    def close(self):
        try: self.page.quit()
        except: pass